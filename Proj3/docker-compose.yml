services:  
  proj3:
    build: .
    container_name: proj3
    environment:
      - BASE_URL=http://host.docker.internal:12434/engines/llama.cpp/v1/
      - MODEL=ai/smollm2:latest 

      - LLM_ZERO=Muslim
      - LLM_ONE=Catholic
      - TOPIC=Eating pork
    depends_on:
      - llm 
  
  llm:
    provider:
      type: model
      options: 
        model: ai/smollm2:latest